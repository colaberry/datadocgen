{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "tags": [
     "desc"
    ]
   },
   "source": [
    "## About the Algorithm\n",
    "\n",
    "Decision trees are amazing tools to easily interpret a model since they split the data based on certain thresholds for each column of the data matrix. They are easy to train with few hyper-parameter and easy to interpret. They do have a major drawback, in that they tend to over fit the data. Despite this, as a first example of a machine learning algorithm, decision trees are intuitive and can give a valuable insight about the data which can be used to build better models. The goal of this analysis is to create a model using a decision tree on a dataset. \n",
    "\n",
    "Introduction to the dataset <br>\n",
    "\n",
    "I will use the sklearn algorithm to train a decision tree. As you will see, many more lines are spent preparing the data for training rather than the actual training process (which really is just one line). The data set we are going to use can be found here -https://data.world/azel/gun-deaths-in-america. This data set is part of five thirty eight's gun deaths in America project. It contains a bunch of information about victims of gun violence. Each row of the dataset contains  the year and month of the shooting, the intent of the shooter, if cops were at the scene or not, the gender, age race and education level of the victim and finally the place where the shooting happened. There is specific information about whether the victim was Hispanic or not. We take this dataset and boil it down to predicting just one of two classes- were the victims of the shooting white or black? Why ignore the other victim classes? (There are 5 in total), firstly, the rest of the classes, as you will see, make up less than 11% of the dataset, secondly the goal is to build a simple binary classification model, for those who are interested, I would love to work with people build a more multi classification model for the whole CDC multiple causes of death dataset <br>\n",
    "\n",
    "\n",
    "The plan for the analysis is as follows:\n",
    "- Read and display the dataset to see what the relevant columns are.\n",
    "- Encode certain categorical variables so the decision tree can be run on them.\n",
    "- Plot some of the categorical variables to see how skewed they are.\n",
    "- Drop rows containing non-white and non-black victims. \n",
    "- Create test and train sets.\n",
    "- Train the decision tree. \n",
    "- Interpret the results of the tree- I will leave that as set of the question so that the interested reader can further get involved with understanding what the model represents\n",
    "\n",
    "### Show class values for race\n",
    "\n",
    "In order to assess the values in the race class, we need to retrieve  the value counts for each of the class variables. This number represents the number of victims of each race, and after retrieval, It is observed that a majority of the victims were either black or white. We can convert  these numbers into percentages and plot them for visualization as well.\n",
    "\n",
    "From the bar plot below, it is obvious that majority of the data is for black or white victims. Here, I would like to point out that we can also make a multiclass problem by sampling the same number of rows as that of the Hispanic victims to create a 3 class classification problem. I chose to just stick with binary classification problem since this is more for demonstration purposes than hardcore analysis of the dataset. \n",
    "\n",
    "Personally, I believe that the complete version of this dataset requires proper analysis so that we can spot some trends on what kind of gun deaths or crimes are prevalent. Based on this if we can build a good prediction model,it can hopefully help law enforcement understand the nature of the problem better. This really is the whole point of the data driven approach. But I digress.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-21T19:52:03.497923Z",
     "start_time": "2018-03-21T19:51:39.312584Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    },
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from io import BytesIO\n",
    "import six\n",
    "from textwrap import dedent as d\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing \n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix,f1_score,recall_score,precision_score,accuracy_score\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO  \n",
    "import seaborn as sns \n",
    "import pydotplus\n",
    "location ='https://raw.githubusercontent.com/colaberry/datadocgen/master/data/fivethirtyEight-gun-violence-data.csv'\n",
    "#load dataset\n",
    "gun_violence_dataset_original= pd.read_csv(location)\n",
    "\n",
    "# remove rows with NA \n",
    "gun_violence_dataset_original = gun_violence_dataset_original.dropna()\n",
    "gun_violence_dataset_original = gun_violence_dataset_original.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "def val_count_to_percent(column): \n",
    "    \"\"\" Convert value counts of a dataframe column to percentages\n",
    "    Input:\n",
    "        column  - Nx1 array, Dataframe column\n",
    "    Output: \n",
    "        percentages- Mx1 array, percentage of value counts for each variable  \n",
    "    \n",
    "    \"\"\"\n",
    "    return pd.value_counts(column)/(pd.value_counts(column).sum())*100 \n",
    "\n",
    "\n",
    "val_count_to_percent(gun_violence_dataset_original['race'])\n",
    "\n",
    "column  = gun_violence_dataset_original['race']\n",
    "fig_width = 18 \n",
    "fig_height = 15\n",
    "save_fig = True\n",
    "figname = 'race'\n",
    "\n",
    "height = np.array(val_count_to_percent(column).values)\n",
    "\n",
    "# sns.plt.figure(figsize=(fig_width,fig_height))\n",
    "hue = list(val_count_to_percent(column).index)\n",
    "mod_hue =[hue[0],hue[1],hue[2],'A/PI', 'NA/NAL'  ]\n",
    "all_data = {'Feature labels':mod_hue , 'Percent of data': height, 'Race': hue}\n",
    "df = pd.DataFrame(data = all_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "plot"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "marker": {
          "color": "rgb(158,202,225)",
          "line": {
           "color": "rgb(8,48,107)",
           "width": 1.5
          }
         },
         "opacity": 0.6,
         "text": [
          "65.93720745296598",
          "23.07359350935647",
          "8.79176187552218",
          "1.3025578047773874",
          "0.8948793573779732"
         ],
         "textposition": "auto",
         "type": "bar",
         "uid": "53ed8a4a-d084-11e8-85ea-b0359f561c51",
         "x": [
          "White",
          "Black",
          "Hispanic",
          "Asian/Pacific Islander",
          "Native American/Native Alaskan"
         ],
         "y": [
          65.93720745296598,
          23.07359350935647,
          8.79176187552218,
          1.3025578047773874,
          0.8948793573779732
         ]
        }
       ],
       "layout": {}
      },
      "text/html": [
       "<div id=\"7ce59500-2a8b-4e93-85e3-1ae3cdc3c984\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"7ce59500-2a8b-4e93-85e3-1ae3cdc3c984\", [{\"marker\": {\"color\": \"rgb(158,202,225)\", \"line\": {\"color\": \"rgb(8,48,107)\", \"width\": 1.5}}, \"opacity\": 0.6, \"text\": [\"65.93720745296598\", \"23.07359350935647\", \"8.79176187552218\", \"1.3025578047773874\", \"0.8948793573779732\"], \"textposition\": \"auto\", \"x\": [\"White\", \"Black\", \"Hispanic\", \"Asian/Pacific Islander\", \"Native American/Native Alaskan\"], \"y\": [65.93720745296598, 23.07359350935647, 8.79176187552218, 1.3025578047773874, 0.8948793573779732], \"type\": \"bar\", \"uid\": \"53ed8a4b-d084-11e8-85ea-b0359f561c51\"}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"7ce59500-2a8b-4e93-85e3-1ae3cdc3c984\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"7ce59500-2a8b-4e93-85e3-1ae3cdc3c984\", [{\"marker\": {\"color\": \"rgb(158,202,225)\", \"line\": {\"color\": \"rgb(8,48,107)\", \"width\": 1.5}}, \"opacity\": 0.6, \"text\": [\"65.93720745296598\", \"23.07359350935647\", \"8.79176187552218\", \"1.3025578047773874\", \"0.8948793573779732\"], \"textposition\": \"auto\", \"x\": [\"White\", \"Black\", \"Hispanic\", \"Asian/Pacific Islander\", \"Native American/Native Alaskan\"], \"y\": [65.93720745296598, 23.07359350935647, 8.79176187552218, 1.3025578047773874, 0.8948793573779732], \"type\": \"bar\", \"uid\": \"53ed8a4b-d084-11e8-85ea-b0359f561c51\"}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "x = df['Race']\n",
    "y = df['Percent of data']\n",
    "\n",
    "def getData():\n",
    "    trace0 = go.Bar(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            text=y,\n",
    "            textposition = 'auto',\n",
    "            marker=dict(\n",
    "                color='rgb(158,202,225)',\n",
    "                line=dict(\n",
    "                    color='rgb(8,48,107)',\n",
    "                    width=1.5),\n",
    "            ),\n",
    "            opacity=0.6\n",
    "        )\n",
    "    data = [trace0]\n",
    "    return data\n",
    "\n",
    "def getLayout():\n",
    "    layout0 = go.Layout(\n",
    "                    scene = dict(\n",
    "                        xaxis = dict(\n",
    "                            title='Radio Spend(x)'),\n",
    "                        yaxis = dict(\n",
    "                            title='TV Spend(y)'),\n",
    "                        zaxis = dict(\n",
    "                            title='Sales(z)')),\n",
    "                margin={'l': 0, 'b': 0, 't': 0, 'r': 0},\n",
    "                #legend={'x': 0, 'y': 1},\n",
    "                hovermode='closest'\n",
    "        )\n",
    "    return layout0\n",
    "\n",
    "iplot({'data' : getData()})"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
